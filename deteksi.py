# -*- coding: utf-8 -*-
"""Deteksi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uIuc9o8XGFBUSzifMfmm0JSiMbWRwSMx
"""

from google.colab import files
uploaded = files.upload()

import zipfile
import os

# Ekstrak zip ke direktori dataset
zip_path = '/content/archive.zip'
extract_path = '/content/dataset'

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Cek hasil ekstraksi
os.listdir('/content/dataset')

import shutil
from sklearn.model_selection import train_test_split
import glob
import os

# Define base directory for extracted content
dataset_base = '/content/dataset/Images'

# Create new folders for train and validation sets
os.makedirs(os.path.join(dataset_base, 'train', 'glasses'), exist_ok=True)
os.makedirs(os.path.join(dataset_base, 'train', 'no_glasses'), exist_ok=True)
os.makedirs(os.path.join(dataset_base, 'validation', 'glasses'), exist_ok=True)
os.makedirs(os.path.join(dataset_base, 'validation', 'no_glasses'), exist_ok=True)

# Function to split data
def split_data(source_dir, train_dir, val_dir, split_ratio=0.6):
    # Check if source directory exists and contains files
    if not os.path.exists(source_dir):
        print(f"Source directory not found: {source_dir}")
        return
    files = glob.glob(os.path.join(source_dir, '*'))
    if not files:
        print(f"No files found in source directory: {source_dir}")
        return

    train_files, val_files = train_test_split(files, train_size=split_ratio, random_state=42)
    for f in train_files:
        shutil.copy(f, train_dir)
    for f in val_files:
        shutil.copy(f, val_dir)

# Define source directories within the extracted Images folder
glasses_source = os.path.join(dataset_base, 'glasses')
no_glasses_source = os.path.join(dataset_base, 'no_glasses')

# Split data for glasses and no_glasses, using the correct paths
split_data(glasses_source,
           os.path.join(dataset_base, 'train', 'glasses'),
           os.path.join(dataset_base, 'validation', 'glasses'))

split_data(no_glasses_source,
           os.path.join(dataset_base, 'train', 'no_glasses'),
           os.path.join(dataset_base, 'validation', 'no_glasses'))

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/content/dataset/Images/train'
val_dir = '/content/dataset/Images/validation'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.Adam(),
    metrics=['accuracy']
)

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

model.save('glasses_classifier.h5')

train_generator.class_indices

import os
import shutil

# Lokasi folder
g_train = '/content/dataset/Images/train/glasses'
ng_train = '/content/dataset/Images/train/no_glasses'
g_val = '/content/dataset/Images/validation/glasses'
ng_val = '/content/dataset/Images/validation/no_glasses'

# Buat folder temp
os.makedirs('/content/temp_g', exist_ok=True)
os.makedirs('/content/temp_ng', exist_ok=True)

# Tukar isi train
shutil.move(g_train, '/content/temp_g')
shutil.move(ng_train, '/content/temp_ng')
shutil.move('/content/temp_g/glasses', ng_train)
shutil.move('/content/temp_ng/no_glasses', g_train)

# Tukar isi validation
shutil.move(g_val, '/content/temp_g_val')
shutil.move(ng_val, '/content/temp_ng_val')
shutil.move('/content/temp_g_val/glasses', ng_val)
shutil.move('/content/temp_ng_val/no_glasses', g_val)



import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/content/dataset/Images/train'
val_dir = '/content/dataset/Images/validation'

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.Adam(),
    metrics=['accuracy']
)

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=val_generator
)

model.save('glasses_classifier_fixed.h5')

